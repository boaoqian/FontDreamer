{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 207500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.012048192771084338,
      "grad_norm": 2.0300657749176025,
      "learning_rate": 2.9927710843373496e-05,
      "loss": 0.1424,
      "step": 500
    },
    {
      "epoch": 0.024096385542168676,
      "grad_norm": 2.6443769931793213,
      "learning_rate": 2.9855421686746988e-05,
      "loss": 0.1073,
      "step": 1000
    },
    {
      "epoch": 0.03614457831325301,
      "grad_norm": 2.355656147003174,
      "learning_rate": 2.9783132530120483e-05,
      "loss": 0.0987,
      "step": 1500
    },
    {
      "epoch": 0.04819277108433735,
      "grad_norm": 2.0099868774414062,
      "learning_rate": 2.971084337349398e-05,
      "loss": 0.0893,
      "step": 2000
    },
    {
      "epoch": 0.060240963855421686,
      "grad_norm": 2.2472734451293945,
      "learning_rate": 2.963855421686747e-05,
      "loss": 0.0918,
      "step": 2500
    },
    {
      "epoch": 0.07228915662650602,
      "grad_norm": 2.6285903453826904,
      "learning_rate": 2.9566265060240966e-05,
      "loss": 0.0879,
      "step": 3000
    },
    {
      "epoch": 0.08433734939759036,
      "grad_norm": 2.4450626373291016,
      "learning_rate": 2.949397590361446e-05,
      "loss": 0.0784,
      "step": 3500
    },
    {
      "epoch": 0.0963855421686747,
      "grad_norm": 0.0,
      "learning_rate": 2.9421686746987953e-05,
      "loss": 0.072,
      "step": 4000
    },
    {
      "epoch": 0.10843373493975904,
      "grad_norm": 1.3626712560653687,
      "learning_rate": 2.9349397590361448e-05,
      "loss": 0.0713,
      "step": 4500
    },
    {
      "epoch": 0.12048192771084337,
      "grad_norm": 0.0,
      "learning_rate": 2.927710843373494e-05,
      "loss": 0.0693,
      "step": 5000
    },
    {
      "epoch": 0.13253012048192772,
      "grad_norm": 3.052260160446167,
      "learning_rate": 2.9204819277108432e-05,
      "loss": 0.0645,
      "step": 5500
    },
    {
      "epoch": 0.14457831325301204,
      "grad_norm": 1.3534282445907593,
      "learning_rate": 2.9132530120481927e-05,
      "loss": 0.0656,
      "step": 6000
    },
    {
      "epoch": 0.1566265060240964,
      "grad_norm": 0.0,
      "learning_rate": 2.9060240963855422e-05,
      "loss": 0.0639,
      "step": 6500
    },
    {
      "epoch": 0.1686746987951807,
      "grad_norm": 2.595423936843872,
      "learning_rate": 2.8987951807228914e-05,
      "loss": 0.0622,
      "step": 7000
    },
    {
      "epoch": 0.18072289156626506,
      "grad_norm": 0.0,
      "learning_rate": 2.891566265060241e-05,
      "loss": 0.0571,
      "step": 7500
    },
    {
      "epoch": 0.1927710843373494,
      "grad_norm": 1.827632188796997,
      "learning_rate": 2.8843373493975905e-05,
      "loss": 0.0606,
      "step": 8000
    },
    {
      "epoch": 0.20481927710843373,
      "grad_norm": 0.8399378657341003,
      "learning_rate": 2.8771084337349397e-05,
      "loss": 0.059,
      "step": 8500
    },
    {
      "epoch": 0.21686746987951808,
      "grad_norm": 1.7753052711486816,
      "learning_rate": 2.8698795180722892e-05,
      "loss": 0.0612,
      "step": 9000
    },
    {
      "epoch": 0.2289156626506024,
      "grad_norm": 0.0,
      "learning_rate": 2.8626506024096387e-05,
      "loss": 0.0533,
      "step": 9500
    },
    {
      "epoch": 0.24096385542168675,
      "grad_norm": 0.0,
      "learning_rate": 2.855421686746988e-05,
      "loss": 0.0501,
      "step": 10000
    },
    {
      "epoch": 0.25301204819277107,
      "grad_norm": 2.276759624481201,
      "learning_rate": 2.8481927710843375e-05,
      "loss": 0.0514,
      "step": 10500
    },
    {
      "epoch": 0.26506024096385544,
      "grad_norm": 0.0,
      "learning_rate": 2.840963855421687e-05,
      "loss": 0.0455,
      "step": 11000
    },
    {
      "epoch": 0.27710843373493976,
      "grad_norm": 2.2335257530212402,
      "learning_rate": 2.8337349397590362e-05,
      "loss": 0.0523,
      "step": 11500
    },
    {
      "epoch": 0.2891566265060241,
      "grad_norm": 2.4300005435943604,
      "learning_rate": 2.8265060240963857e-05,
      "loss": 0.0554,
      "step": 12000
    },
    {
      "epoch": 0.30120481927710846,
      "grad_norm": 0.0,
      "learning_rate": 2.8192771084337352e-05,
      "loss": 0.0478,
      "step": 12500
    },
    {
      "epoch": 0.3132530120481928,
      "grad_norm": 1.3828126192092896,
      "learning_rate": 2.8120481927710844e-05,
      "loss": 0.0485,
      "step": 13000
    },
    {
      "epoch": 0.3253012048192771,
      "grad_norm": 2.170668125152588,
      "learning_rate": 2.804819277108434e-05,
      "loss": 0.0521,
      "step": 13500
    },
    {
      "epoch": 0.3373493975903614,
      "grad_norm": 2.598205804824829,
      "learning_rate": 2.797590361445783e-05,
      "loss": 0.0469,
      "step": 14000
    },
    {
      "epoch": 0.3493975903614458,
      "grad_norm": 1.897371768951416,
      "learning_rate": 2.7903614457831323e-05,
      "loss": 0.0506,
      "step": 14500
    },
    {
      "epoch": 0.3614457831325301,
      "grad_norm": 2.187947988510132,
      "learning_rate": 2.783132530120482e-05,
      "loss": 0.0431,
      "step": 15000
    },
    {
      "epoch": 0.37349397590361444,
      "grad_norm": 1.9336034059524536,
      "learning_rate": 2.7759036144578314e-05,
      "loss": 0.0433,
      "step": 15500
    },
    {
      "epoch": 0.3855421686746988,
      "grad_norm": 1.4744645357131958,
      "learning_rate": 2.7686746987951806e-05,
      "loss": 0.0458,
      "step": 16000
    },
    {
      "epoch": 0.39759036144578314,
      "grad_norm": 0.0,
      "learning_rate": 2.76144578313253e-05,
      "loss": 0.0469,
      "step": 16500
    },
    {
      "epoch": 0.40963855421686746,
      "grad_norm": 0.0,
      "learning_rate": 2.7542168674698796e-05,
      "loss": 0.0467,
      "step": 17000
    },
    {
      "epoch": 0.42168674698795183,
      "grad_norm": 0.0,
      "learning_rate": 2.7469879518072288e-05,
      "loss": 0.041,
      "step": 17500
    },
    {
      "epoch": 0.43373493975903615,
      "grad_norm": 3.0846269130706787,
      "learning_rate": 2.7397590361445783e-05,
      "loss": 0.0416,
      "step": 18000
    },
    {
      "epoch": 0.4457831325301205,
      "grad_norm": 1.6930091381072998,
      "learning_rate": 2.732530120481928e-05,
      "loss": 0.048,
      "step": 18500
    },
    {
      "epoch": 0.4578313253012048,
      "grad_norm": 2.3583791255950928,
      "learning_rate": 2.725301204819277e-05,
      "loss": 0.0465,
      "step": 19000
    },
    {
      "epoch": 0.46987951807228917,
      "grad_norm": 0.0,
      "learning_rate": 2.7180722891566266e-05,
      "loss": 0.0411,
      "step": 19500
    },
    {
      "epoch": 0.4819277108433735,
      "grad_norm": 3.4855058193206787,
      "learning_rate": 2.710843373493976e-05,
      "loss": 0.0398,
      "step": 20000
    },
    {
      "epoch": 0.4939759036144578,
      "grad_norm": 0.0,
      "learning_rate": 2.7036144578313253e-05,
      "loss": 0.0363,
      "step": 20500
    },
    {
      "epoch": 0.5060240963855421,
      "grad_norm": 0.0,
      "learning_rate": 2.696385542168675e-05,
      "loss": 0.0364,
      "step": 21000
    },
    {
      "epoch": 0.5180722891566265,
      "grad_norm": 2.1424922943115234,
      "learning_rate": 2.6891566265060244e-05,
      "loss": 0.0375,
      "step": 21500
    },
    {
      "epoch": 0.5301204819277109,
      "grad_norm": 0.0,
      "learning_rate": 2.6819277108433735e-05,
      "loss": 0.0378,
      "step": 22000
    },
    {
      "epoch": 0.5421686746987951,
      "grad_norm": 0.0,
      "learning_rate": 2.674698795180723e-05,
      "loss": 0.039,
      "step": 22500
    },
    {
      "epoch": 0.5542168674698795,
      "grad_norm": 2.859607219696045,
      "learning_rate": 2.6674698795180723e-05,
      "loss": 0.041,
      "step": 23000
    },
    {
      "epoch": 0.5662650602409639,
      "grad_norm": 2.485758066177368,
      "learning_rate": 2.6602409638554215e-05,
      "loss": 0.0417,
      "step": 23500
    },
    {
      "epoch": 0.5783132530120482,
      "grad_norm": 3.545001268386841,
      "learning_rate": 2.653012048192771e-05,
      "loss": 0.0356,
      "step": 24000
    },
    {
      "epoch": 0.5903614457831325,
      "grad_norm": 2.333742380142212,
      "learning_rate": 2.6457831325301205e-05,
      "loss": 0.0402,
      "step": 24500
    },
    {
      "epoch": 0.6024096385542169,
      "grad_norm": 1.8988717794418335,
      "learning_rate": 2.6385542168674697e-05,
      "loss": 0.036,
      "step": 25000
    },
    {
      "epoch": 0.6144578313253012,
      "grad_norm": 0.0,
      "learning_rate": 2.6313253012048192e-05,
      "loss": 0.0356,
      "step": 25500
    },
    {
      "epoch": 0.6265060240963856,
      "grad_norm": 2.156980514526367,
      "learning_rate": 2.6240963855421688e-05,
      "loss": 0.0356,
      "step": 26000
    },
    {
      "epoch": 0.6385542168674698,
      "grad_norm": 0.0,
      "learning_rate": 2.6168674698795183e-05,
      "loss": 0.0375,
      "step": 26500
    },
    {
      "epoch": 0.6506024096385542,
      "grad_norm": 0.0,
      "learning_rate": 2.6096385542168675e-05,
      "loss": 0.0354,
      "step": 27000
    },
    {
      "epoch": 0.6626506024096386,
      "grad_norm": 0.0,
      "learning_rate": 2.602409638554217e-05,
      "loss": 0.0307,
      "step": 27500
    },
    {
      "epoch": 0.6746987951807228,
      "grad_norm": 0.0,
      "learning_rate": 2.5951807228915665e-05,
      "loss": 0.038,
      "step": 28000
    },
    {
      "epoch": 0.6867469879518072,
      "grad_norm": 0.0,
      "learning_rate": 2.5879518072289157e-05,
      "loss": 0.0325,
      "step": 28500
    },
    {
      "epoch": 0.6987951807228916,
      "grad_norm": 0.0,
      "learning_rate": 2.5807228915662652e-05,
      "loss": 0.0363,
      "step": 29000
    },
    {
      "epoch": 0.7108433734939759,
      "grad_norm": 2.723224639892578,
      "learning_rate": 2.5734939759036148e-05,
      "loss": 0.0333,
      "step": 29500
    },
    {
      "epoch": 0.7228915662650602,
      "grad_norm": 3.82802414894104,
      "learning_rate": 2.566265060240964e-05,
      "loss": 0.0313,
      "step": 30000
    },
    {
      "epoch": 0.7349397590361446,
      "grad_norm": 0.0,
      "learning_rate": 2.5590361445783135e-05,
      "loss": 0.0312,
      "step": 30500
    },
    {
      "epoch": 0.7469879518072289,
      "grad_norm": 3.161137580871582,
      "learning_rate": 2.551807228915663e-05,
      "loss": 0.035,
      "step": 31000
    },
    {
      "epoch": 0.7590361445783133,
      "grad_norm": 0.0,
      "learning_rate": 2.5445783132530122e-05,
      "loss": 0.032,
      "step": 31500
    },
    {
      "epoch": 0.7710843373493976,
      "grad_norm": 3.4074556827545166,
      "learning_rate": 2.5373493975903614e-05,
      "loss": 0.0343,
      "step": 32000
    },
    {
      "epoch": 0.7831325301204819,
      "grad_norm": 0.0,
      "learning_rate": 2.530120481927711e-05,
      "loss": 0.0322,
      "step": 32500
    },
    {
      "epoch": 0.7951807228915663,
      "grad_norm": 2.2854504585266113,
      "learning_rate": 2.52289156626506e-05,
      "loss": 0.0268,
      "step": 33000
    },
    {
      "epoch": 0.8072289156626506,
      "grad_norm": 1.809799075126648,
      "learning_rate": 2.5156626506024096e-05,
      "loss": 0.032,
      "step": 33500
    },
    {
      "epoch": 0.8192771084337349,
      "grad_norm": 2.065509080886841,
      "learning_rate": 2.5084337349397592e-05,
      "loss": 0.0311,
      "step": 34000
    },
    {
      "epoch": 0.8313253012048193,
      "grad_norm": 0.0,
      "learning_rate": 2.5012048192771084e-05,
      "loss": 0.0322,
      "step": 34500
    },
    {
      "epoch": 0.8433734939759037,
      "grad_norm": 0.0,
      "learning_rate": 2.493975903614458e-05,
      "loss": 0.031,
      "step": 35000
    },
    {
      "epoch": 0.8554216867469879,
      "grad_norm": 0.0,
      "learning_rate": 2.4867469879518074e-05,
      "loss": 0.033,
      "step": 35500
    },
    {
      "epoch": 0.8674698795180723,
      "grad_norm": 0.0,
      "learning_rate": 2.4795180722891566e-05,
      "loss": 0.0297,
      "step": 36000
    },
    {
      "epoch": 0.8795180722891566,
      "grad_norm": 0.0,
      "learning_rate": 2.472289156626506e-05,
      "loss": 0.0314,
      "step": 36500
    },
    {
      "epoch": 0.891566265060241,
      "grad_norm": 0.0,
      "learning_rate": 2.4650602409638557e-05,
      "loss": 0.0298,
      "step": 37000
    },
    {
      "epoch": 0.9036144578313253,
      "grad_norm": 3.035752773284912,
      "learning_rate": 2.457831325301205e-05,
      "loss": 0.0283,
      "step": 37500
    },
    {
      "epoch": 0.9156626506024096,
      "grad_norm": 3.9296393394470215,
      "learning_rate": 2.4506024096385544e-05,
      "loss": 0.0285,
      "step": 38000
    },
    {
      "epoch": 0.927710843373494,
      "grad_norm": 4.084991931915283,
      "learning_rate": 2.443373493975904e-05,
      "loss": 0.0304,
      "step": 38500
    },
    {
      "epoch": 0.9397590361445783,
      "grad_norm": 4.382625579833984,
      "learning_rate": 2.436144578313253e-05,
      "loss": 0.0279,
      "step": 39000
    },
    {
      "epoch": 0.9518072289156626,
      "grad_norm": 0.0,
      "learning_rate": 2.4289156626506026e-05,
      "loss": 0.0269,
      "step": 39500
    },
    {
      "epoch": 0.963855421686747,
      "grad_norm": 0.0,
      "learning_rate": 2.421686746987952e-05,
      "loss": 0.0283,
      "step": 40000
    },
    {
      "epoch": 0.9759036144578314,
      "grad_norm": 1.9102991819381714,
      "learning_rate": 2.4144578313253013e-05,
      "loss": 0.0304,
      "step": 40500
    },
    {
      "epoch": 0.9879518072289156,
      "grad_norm": 0.0,
      "learning_rate": 2.4072289156626505e-05,
      "loss": 0.0288,
      "step": 41000
    },
    {
      "epoch": 1.0,
      "grad_norm": 3.146449565887451,
      "learning_rate": 2.4e-05,
      "loss": 0.0315,
      "step": 41500
    },
    {
      "epoch": 1.0120481927710843,
      "grad_norm": 3.050365686416626,
      "learning_rate": 2.3927710843373493e-05,
      "loss": 0.0282,
      "step": 42000
    },
    {
      "epoch": 1.0240963855421688,
      "grad_norm": 1.8109530210494995,
      "learning_rate": 2.3855421686746988e-05,
      "loss": 0.0265,
      "step": 42500
    },
    {
      "epoch": 1.036144578313253,
      "grad_norm": 0.0,
      "learning_rate": 2.3783132530120483e-05,
      "loss": 0.0266,
      "step": 43000
    },
    {
      "epoch": 1.0481927710843373,
      "grad_norm": 0.0,
      "learning_rate": 2.3710843373493975e-05,
      "loss": 0.0264,
      "step": 43500
    },
    {
      "epoch": 1.0602409638554218,
      "grad_norm": 0.0,
      "learning_rate": 2.363855421686747e-05,
      "loss": 0.0298,
      "step": 44000
    },
    {
      "epoch": 1.072289156626506,
      "grad_norm": 3.5745205879211426,
      "learning_rate": 2.3566265060240966e-05,
      "loss": 0.0272,
      "step": 44500
    },
    {
      "epoch": 1.0843373493975903,
      "grad_norm": 1.8306154012680054,
      "learning_rate": 2.3493975903614457e-05,
      "loss": 0.0258,
      "step": 45000
    },
    {
      "epoch": 1.0963855421686748,
      "grad_norm": 0.0,
      "learning_rate": 2.3421686746987953e-05,
      "loss": 0.0251,
      "step": 45500
    },
    {
      "epoch": 1.108433734939759,
      "grad_norm": 0.0,
      "learning_rate": 2.3349397590361448e-05,
      "loss": 0.0238,
      "step": 46000
    },
    {
      "epoch": 1.1204819277108433,
      "grad_norm": 0.0,
      "learning_rate": 2.327710843373494e-05,
      "loss": 0.029,
      "step": 46500
    },
    {
      "epoch": 1.1325301204819278,
      "grad_norm": 2.6396381855010986,
      "learning_rate": 2.3204819277108435e-05,
      "loss": 0.0246,
      "step": 47000
    },
    {
      "epoch": 1.144578313253012,
      "grad_norm": 3.5303685665130615,
      "learning_rate": 2.313253012048193e-05,
      "loss": 0.0249,
      "step": 47500
    },
    {
      "epoch": 1.1566265060240963,
      "grad_norm": 0.0,
      "learning_rate": 2.3060240963855422e-05,
      "loss": 0.0278,
      "step": 48000
    },
    {
      "epoch": 1.1686746987951806,
      "grad_norm": 0.0,
      "learning_rate": 2.2987951807228918e-05,
      "loss": 0.0257,
      "step": 48500
    },
    {
      "epoch": 1.180722891566265,
      "grad_norm": 0.0,
      "learning_rate": 2.2915662650602413e-05,
      "loss": 0.0282,
      "step": 49000
    },
    {
      "epoch": 1.1927710843373494,
      "grad_norm": 1.5980067253112793,
      "learning_rate": 2.2843373493975905e-05,
      "loss": 0.0278,
      "step": 49500
    },
    {
      "epoch": 1.2048192771084336,
      "grad_norm": 0.0,
      "learning_rate": 2.2771084337349397e-05,
      "loss": 0.0286,
      "step": 50000
    },
    {
      "epoch": 1.216867469879518,
      "grad_norm": 0.0,
      "learning_rate": 2.2698795180722892e-05,
      "loss": 0.0222,
      "step": 50500
    },
    {
      "epoch": 1.2289156626506024,
      "grad_norm": 0.0,
      "learning_rate": 2.2626506024096384e-05,
      "loss": 0.0254,
      "step": 51000
    },
    {
      "epoch": 1.2409638554216866,
      "grad_norm": 0.0,
      "learning_rate": 2.255421686746988e-05,
      "loss": 0.0293,
      "step": 51500
    },
    {
      "epoch": 1.2530120481927711,
      "grad_norm": 4.586054801940918,
      "learning_rate": 2.2481927710843374e-05,
      "loss": 0.0275,
      "step": 52000
    },
    {
      "epoch": 1.2650602409638554,
      "grad_norm": 2.5275068283081055,
      "learning_rate": 2.2409638554216866e-05,
      "loss": 0.0269,
      "step": 52500
    },
    {
      "epoch": 1.2771084337349397,
      "grad_norm": 0.0,
      "learning_rate": 2.233734939759036e-05,
      "loss": 0.0244,
      "step": 53000
    },
    {
      "epoch": 1.2891566265060241,
      "grad_norm": 0.0,
      "learning_rate": 2.2265060240963857e-05,
      "loss": 0.0256,
      "step": 53500
    },
    {
      "epoch": 1.3012048192771084,
      "grad_norm": 3.4899442195892334,
      "learning_rate": 2.219277108433735e-05,
      "loss": 0.0247,
      "step": 54000
    },
    {
      "epoch": 1.3132530120481927,
      "grad_norm": 0.0,
      "learning_rate": 2.2120481927710844e-05,
      "loss": 0.0238,
      "step": 54500
    },
    {
      "epoch": 1.3253012048192772,
      "grad_norm": 2.8102917671203613,
      "learning_rate": 2.204819277108434e-05,
      "loss": 0.0247,
      "step": 55000
    },
    {
      "epoch": 1.3373493975903614,
      "grad_norm": 0.0,
      "learning_rate": 2.197590361445783e-05,
      "loss": 0.0243,
      "step": 55500
    },
    {
      "epoch": 1.3493975903614457,
      "grad_norm": 2.1640233993530273,
      "learning_rate": 2.1903614457831326e-05,
      "loss": 0.0251,
      "step": 56000
    },
    {
      "epoch": 1.3614457831325302,
      "grad_norm": 2.0076472759246826,
      "learning_rate": 2.1831325301204822e-05,
      "loss": 0.0238,
      "step": 56500
    },
    {
      "epoch": 1.3734939759036144,
      "grad_norm": 0.0,
      "learning_rate": 2.1759036144578314e-05,
      "loss": 0.0295,
      "step": 57000
    },
    {
      "epoch": 1.3855421686746987,
      "grad_norm": 4.455356597900391,
      "learning_rate": 2.168674698795181e-05,
      "loss": 0.0244,
      "step": 57500
    },
    {
      "epoch": 1.3975903614457832,
      "grad_norm": 2.2812700271606445,
      "learning_rate": 2.1614457831325304e-05,
      "loss": 0.0283,
      "step": 58000
    },
    {
      "epoch": 1.4096385542168675,
      "grad_norm": 3.118474006652832,
      "learning_rate": 2.1542168674698796e-05,
      "loss": 0.0245,
      "step": 58500
    },
    {
      "epoch": 1.4216867469879517,
      "grad_norm": 0.0,
      "learning_rate": 2.1469879518072288e-05,
      "loss": 0.0263,
      "step": 59000
    },
    {
      "epoch": 1.4337349397590362,
      "grad_norm": 0.0,
      "learning_rate": 2.1397590361445783e-05,
      "loss": 0.0236,
      "step": 59500
    },
    {
      "epoch": 1.4457831325301205,
      "grad_norm": 0.0,
      "learning_rate": 2.1325301204819275e-05,
      "loss": 0.0235,
      "step": 60000
    },
    {
      "epoch": 1.4578313253012047,
      "grad_norm": 0.0,
      "learning_rate": 2.125301204819277e-05,
      "loss": 0.0216,
      "step": 60500
    },
    {
      "epoch": 1.4698795180722892,
      "grad_norm": 0.0,
      "learning_rate": 2.1180722891566266e-05,
      "loss": 0.025,
      "step": 61000
    },
    {
      "epoch": 1.4819277108433735,
      "grad_norm": 2.65232515335083,
      "learning_rate": 2.1108433734939758e-05,
      "loss": 0.0254,
      "step": 61500
    },
    {
      "epoch": 1.4939759036144578,
      "grad_norm": 2.0677130222320557,
      "learning_rate": 2.1036144578313253e-05,
      "loss": 0.0309,
      "step": 62000
    },
    {
      "epoch": 1.5060240963855422,
      "grad_norm": 0.0,
      "learning_rate": 2.0963855421686748e-05,
      "loss": 0.0284,
      "step": 62500
    },
    {
      "epoch": 1.5180722891566265,
      "grad_norm": 2.3747568130493164,
      "learning_rate": 2.089156626506024e-05,
      "loss": 0.0256,
      "step": 63000
    },
    {
      "epoch": 1.5301204819277108,
      "grad_norm": 0.0,
      "learning_rate": 2.0819277108433735e-05,
      "loss": 0.0245,
      "step": 63500
    },
    {
      "epoch": 1.5421686746987953,
      "grad_norm": 0.0,
      "learning_rate": 2.074698795180723e-05,
      "loss": 0.0216,
      "step": 64000
    },
    {
      "epoch": 1.5542168674698795,
      "grad_norm": 0.0,
      "learning_rate": 2.0674698795180723e-05,
      "loss": 0.0203,
      "step": 64500
    },
    {
      "epoch": 1.5662650602409638,
      "grad_norm": 2.325517177581787,
      "learning_rate": 2.0602409638554218e-05,
      "loss": 0.0238,
      "step": 65000
    },
    {
      "epoch": 1.5783132530120483,
      "grad_norm": 0.0,
      "learning_rate": 2.0530120481927713e-05,
      "loss": 0.0254,
      "step": 65500
    },
    {
      "epoch": 1.5903614457831325,
      "grad_norm": 2.045625925064087,
      "learning_rate": 2.0457831325301205e-05,
      "loss": 0.0239,
      "step": 66000
    },
    {
      "epoch": 1.6024096385542168,
      "grad_norm": 1.8577467203140259,
      "learning_rate": 2.03855421686747e-05,
      "loss": 0.0236,
      "step": 66500
    },
    {
      "epoch": 1.6144578313253013,
      "grad_norm": 3.75834584236145,
      "learning_rate": 2.0313253012048196e-05,
      "loss": 0.0254,
      "step": 67000
    },
    {
      "epoch": 1.6265060240963856,
      "grad_norm": 3.0408225059509277,
      "learning_rate": 2.0240963855421687e-05,
      "loss": 0.0283,
      "step": 67500
    },
    {
      "epoch": 1.6385542168674698,
      "grad_norm": 4.132087707519531,
      "learning_rate": 2.016867469879518e-05,
      "loss": 0.0232,
      "step": 68000
    },
    {
      "epoch": 1.6506024096385543,
      "grad_norm": 0.0,
      "learning_rate": 2.0096385542168675e-05,
      "loss": 0.0205,
      "step": 68500
    },
    {
      "epoch": 1.6626506024096386,
      "grad_norm": 0.0,
      "learning_rate": 2.0024096385542166e-05,
      "loss": 0.024,
      "step": 69000
    },
    {
      "epoch": 1.6746987951807228,
      "grad_norm": 3.651411771774292,
      "learning_rate": 1.9951807228915662e-05,
      "loss": 0.0224,
      "step": 69500
    },
    {
      "epoch": 1.6867469879518073,
      "grad_norm": 0.0,
      "learning_rate": 1.9879518072289157e-05,
      "loss": 0.0207,
      "step": 70000
    },
    {
      "epoch": 1.6987951807228916,
      "grad_norm": 0.0,
      "learning_rate": 1.980722891566265e-05,
      "loss": 0.0216,
      "step": 70500
    },
    {
      "epoch": 1.7108433734939759,
      "grad_norm": 2.678358316421509,
      "learning_rate": 1.9734939759036144e-05,
      "loss": 0.0246,
      "step": 71000
    },
    {
      "epoch": 1.7228915662650603,
      "grad_norm": 1.8355661630630493,
      "learning_rate": 1.966265060240964e-05,
      "loss": 0.0297,
      "step": 71500
    },
    {
      "epoch": 1.7349397590361446,
      "grad_norm": 1.5524015426635742,
      "learning_rate": 1.959036144578313e-05,
      "loss": 0.0188,
      "step": 72000
    },
    {
      "epoch": 1.7469879518072289,
      "grad_norm": 0.0,
      "learning_rate": 1.9518072289156627e-05,
      "loss": 0.0197,
      "step": 72500
    },
    {
      "epoch": 1.7590361445783134,
      "grad_norm": 0.0,
      "learning_rate": 1.9445783132530122e-05,
      "loss": 0.0216,
      "step": 73000
    },
    {
      "epoch": 1.7710843373493976,
      "grad_norm": 0.0,
      "learning_rate": 1.9373493975903614e-05,
      "loss": 0.0223,
      "step": 73500
    },
    {
      "epoch": 1.783132530120482,
      "grad_norm": 0.0,
      "learning_rate": 1.930120481927711e-05,
      "loss": 0.0221,
      "step": 74000
    },
    {
      "epoch": 1.7951807228915664,
      "grad_norm": 0.0,
      "learning_rate": 1.9228915662650604e-05,
      "loss": 0.0235,
      "step": 74500
    },
    {
      "epoch": 1.8072289156626506,
      "grad_norm": 2.3254053592681885,
      "learning_rate": 1.9156626506024096e-05,
      "loss": 0.0195,
      "step": 75000
    },
    {
      "epoch": 1.819277108433735,
      "grad_norm": 0.0,
      "learning_rate": 1.908433734939759e-05,
      "loss": 0.0217,
      "step": 75500
    },
    {
      "epoch": 1.8313253012048194,
      "grad_norm": 1.7740492820739746,
      "learning_rate": 1.9012048192771087e-05,
      "loss": 0.0212,
      "step": 76000
    },
    {
      "epoch": 1.8433734939759037,
      "grad_norm": 0.0,
      "learning_rate": 1.893975903614458e-05,
      "loss": 0.0233,
      "step": 76500
    },
    {
      "epoch": 1.855421686746988,
      "grad_norm": 0.0,
      "learning_rate": 1.886746987951807e-05,
      "loss": 0.0237,
      "step": 77000
    },
    {
      "epoch": 1.8674698795180724,
      "grad_norm": 0.0,
      "learning_rate": 1.8795180722891566e-05,
      "loss": 0.022,
      "step": 77500
    },
    {
      "epoch": 1.8795180722891565,
      "grad_norm": 0.0,
      "learning_rate": 1.872289156626506e-05,
      "loss": 0.0217,
      "step": 78000
    },
    {
      "epoch": 1.891566265060241,
      "grad_norm": 0.0,
      "learning_rate": 1.8650602409638553e-05,
      "loss": 0.0257,
      "step": 78500
    },
    {
      "epoch": 1.9036144578313254,
      "grad_norm": 0.0,
      "learning_rate": 1.857831325301205e-05,
      "loss": 0.0233,
      "step": 79000
    },
    {
      "epoch": 1.9156626506024095,
      "grad_norm": 2.0546562671661377,
      "learning_rate": 1.8506024096385544e-05,
      "loss": 0.0222,
      "step": 79500
    },
    {
      "epoch": 1.927710843373494,
      "grad_norm": 0.0,
      "learning_rate": 1.8433734939759036e-05,
      "loss": 0.0218,
      "step": 80000
    },
    {
      "epoch": 1.9397590361445785,
      "grad_norm": 0.0,
      "learning_rate": 1.836144578313253e-05,
      "loss": 0.0214,
      "step": 80500
    },
    {
      "epoch": 1.9518072289156625,
      "grad_norm": 1.3550184965133667,
      "learning_rate": 1.8289156626506026e-05,
      "loss": 0.02,
      "step": 81000
    },
    {
      "epoch": 1.963855421686747,
      "grad_norm": 0.0,
      "learning_rate": 1.8216867469879518e-05,
      "loss": 0.0199,
      "step": 81500
    },
    {
      "epoch": 1.9759036144578315,
      "grad_norm": 4.673854827880859,
      "learning_rate": 1.8144578313253013e-05,
      "loss": 0.0209,
      "step": 82000
    },
    {
      "epoch": 1.9879518072289155,
      "grad_norm": 0.0,
      "learning_rate": 1.807228915662651e-05,
      "loss": 0.0205,
      "step": 82500
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.0,
      "learning_rate": 1.8e-05,
      "loss": 0.0187,
      "step": 83000
    },
    {
      "epoch": 2.0120481927710845,
      "grad_norm": 0.0,
      "learning_rate": 1.7927710843373496e-05,
      "loss": 0.0182,
      "step": 83500
    },
    {
      "epoch": 2.0240963855421685,
      "grad_norm": 0.0,
      "learning_rate": 1.785542168674699e-05,
      "loss": 0.022,
      "step": 84000
    },
    {
      "epoch": 2.036144578313253,
      "grad_norm": 0.0,
      "learning_rate": 1.7783132530120483e-05,
      "loss": 0.0175,
      "step": 84500
    },
    {
      "epoch": 2.0481927710843375,
      "grad_norm": 0.0,
      "learning_rate": 1.7710843373493978e-05,
      "loss": 0.022,
      "step": 85000
    },
    {
      "epoch": 2.0602409638554215,
      "grad_norm": 0.0,
      "learning_rate": 1.7638554216867473e-05,
      "loss": 0.0231,
      "step": 85500
    },
    {
      "epoch": 2.072289156626506,
      "grad_norm": 1.8209294080734253,
      "learning_rate": 1.7566265060240962e-05,
      "loss": 0.024,
      "step": 86000
    },
    {
      "epoch": 2.0843373493975905,
      "grad_norm": 0.0,
      "learning_rate": 1.7493975903614457e-05,
      "loss": 0.0215,
      "step": 86500
    },
    {
      "epoch": 2.0963855421686746,
      "grad_norm": 0.0,
      "learning_rate": 1.7421686746987953e-05,
      "loss": 0.0234,
      "step": 87000
    },
    {
      "epoch": 2.108433734939759,
      "grad_norm": 2.7511425018310547,
      "learning_rate": 1.7349397590361444e-05,
      "loss": 0.0217,
      "step": 87500
    },
    {
      "epoch": 2.1204819277108435,
      "grad_norm": 0.0,
      "learning_rate": 1.727710843373494e-05,
      "loss": 0.0187,
      "step": 88000
    },
    {
      "epoch": 2.1325301204819276,
      "grad_norm": 3.320758581161499,
      "learning_rate": 1.7204819277108435e-05,
      "loss": 0.0215,
      "step": 88500
    },
    {
      "epoch": 2.144578313253012,
      "grad_norm": 2.181560516357422,
      "learning_rate": 1.7132530120481927e-05,
      "loss": 0.023,
      "step": 89000
    },
    {
      "epoch": 2.1566265060240966,
      "grad_norm": 0.0,
      "learning_rate": 1.7060240963855422e-05,
      "loss": 0.0205,
      "step": 89500
    },
    {
      "epoch": 2.1686746987951806,
      "grad_norm": 0.0,
      "learning_rate": 1.6987951807228917e-05,
      "loss": 0.0196,
      "step": 90000
    },
    {
      "epoch": 2.180722891566265,
      "grad_norm": 0.0,
      "learning_rate": 1.691566265060241e-05,
      "loss": 0.0215,
      "step": 90500
    },
    {
      "epoch": 2.1927710843373496,
      "grad_norm": 2.2032077312469482,
      "learning_rate": 1.6843373493975905e-05,
      "loss": 0.0203,
      "step": 91000
    },
    {
      "epoch": 2.2048192771084336,
      "grad_norm": 0.0,
      "learning_rate": 1.67710843373494e-05,
      "loss": 0.0193,
      "step": 91500
    },
    {
      "epoch": 2.216867469879518,
      "grad_norm": 0.0,
      "learning_rate": 1.6698795180722892e-05,
      "loss": 0.0218,
      "step": 92000
    },
    {
      "epoch": 2.2289156626506026,
      "grad_norm": 2.702894449234009,
      "learning_rate": 1.6626506024096387e-05,
      "loss": 0.0204,
      "step": 92500
    },
    {
      "epoch": 2.2409638554216866,
      "grad_norm": 0.0,
      "learning_rate": 1.6554216867469882e-05,
      "loss": 0.0199,
      "step": 93000
    },
    {
      "epoch": 2.253012048192771,
      "grad_norm": 0.0,
      "learning_rate": 1.6481927710843374e-05,
      "loss": 0.0201,
      "step": 93500
    },
    {
      "epoch": 2.2650602409638556,
      "grad_norm": 2.4593517780303955,
      "learning_rate": 1.640963855421687e-05,
      "loss": 0.018,
      "step": 94000
    },
    {
      "epoch": 2.2771084337349397,
      "grad_norm": 0.0,
      "learning_rate": 1.6337349397590365e-05,
      "loss": 0.0223,
      "step": 94500
    },
    {
      "epoch": 2.289156626506024,
      "grad_norm": 3.491729974746704,
      "learning_rate": 1.6265060240963853e-05,
      "loss": 0.0203,
      "step": 95000
    },
    {
      "epoch": 2.3012048192771086,
      "grad_norm": 2.102073907852173,
      "learning_rate": 1.619277108433735e-05,
      "loss": 0.0242,
      "step": 95500
    },
    {
      "epoch": 2.3132530120481927,
      "grad_norm": 0.0,
      "learning_rate": 1.6120481927710844e-05,
      "loss": 0.0231,
      "step": 96000
    },
    {
      "epoch": 2.325301204819277,
      "grad_norm": 2.613985061645508,
      "learning_rate": 1.6048192771084336e-05,
      "loss": 0.0216,
      "step": 96500
    },
    {
      "epoch": 2.337349397590361,
      "grad_norm": 0.0,
      "learning_rate": 1.597590361445783e-05,
      "loss": 0.0182,
      "step": 97000
    },
    {
      "epoch": 2.3493975903614457,
      "grad_norm": 3.158830165863037,
      "learning_rate": 1.5903614457831326e-05,
      "loss": 0.0227,
      "step": 97500
    },
    {
      "epoch": 2.36144578313253,
      "grad_norm": 0.0,
      "learning_rate": 1.5831325301204818e-05,
      "loss": 0.0226,
      "step": 98000
    },
    {
      "epoch": 2.3734939759036147,
      "grad_norm": 4.089319229125977,
      "learning_rate": 1.5759036144578313e-05,
      "loss": 0.0234,
      "step": 98500
    },
    {
      "epoch": 2.3855421686746987,
      "grad_norm": 4.230306625366211,
      "learning_rate": 1.568674698795181e-05,
      "loss": 0.021,
      "step": 99000
    },
    {
      "epoch": 2.397590361445783,
      "grad_norm": 0.0,
      "learning_rate": 1.56144578313253e-05,
      "loss": 0.0211,
      "step": 99500
    },
    {
      "epoch": 2.4096385542168672,
      "grad_norm": 0.0,
      "learning_rate": 1.5542168674698796e-05,
      "loss": 0.0221,
      "step": 100000
    },
    {
      "epoch": 2.4216867469879517,
      "grad_norm": 0.0,
      "learning_rate": 1.546987951807229e-05,
      "loss": 0.016,
      "step": 100500
    },
    {
      "epoch": 2.433734939759036,
      "grad_norm": 0.0,
      "learning_rate": 1.5397590361445783e-05,
      "loss": 0.0194,
      "step": 101000
    },
    {
      "epoch": 2.4457831325301207,
      "grad_norm": 3.3158438205718994,
      "learning_rate": 1.532530120481928e-05,
      "loss": 0.0166,
      "step": 101500
    },
    {
      "epoch": 2.4578313253012047,
      "grad_norm": 0.0,
      "learning_rate": 1.5253012048192772e-05,
      "loss": 0.0214,
      "step": 102000
    },
    {
      "epoch": 2.4698795180722892,
      "grad_norm": 0.0,
      "learning_rate": 1.5180722891566264e-05,
      "loss": 0.0184,
      "step": 102500
    },
    {
      "epoch": 2.4819277108433733,
      "grad_norm": 0.0,
      "learning_rate": 1.510843373493976e-05,
      "loss": 0.0211,
      "step": 103000
    },
    {
      "epoch": 2.4939759036144578,
      "grad_norm": 0.0,
      "learning_rate": 1.5036144578313254e-05,
      "loss": 0.0212,
      "step": 103500
    },
    {
      "epoch": 2.5060240963855422,
      "grad_norm": 0.0,
      "learning_rate": 1.4963855421686748e-05,
      "loss": 0.0173,
      "step": 104000
    },
    {
      "epoch": 2.5180722891566267,
      "grad_norm": 5.178210735321045,
      "learning_rate": 1.4891566265060242e-05,
      "loss": 0.02,
      "step": 104500
    },
    {
      "epoch": 2.5301204819277108,
      "grad_norm": 1.3837640285491943,
      "learning_rate": 1.4819277108433735e-05,
      "loss": 0.0208,
      "step": 105000
    },
    {
      "epoch": 2.5421686746987953,
      "grad_norm": 0.0,
      "learning_rate": 1.474698795180723e-05,
      "loss": 0.0212,
      "step": 105500
    },
    {
      "epoch": 2.5542168674698793,
      "grad_norm": 0.0,
      "learning_rate": 1.4674698795180724e-05,
      "loss": 0.0189,
      "step": 106000
    },
    {
      "epoch": 2.566265060240964,
      "grad_norm": 2.5024075508117676,
      "learning_rate": 1.4602409638554216e-05,
      "loss": 0.0196,
      "step": 106500
    },
    {
      "epoch": 2.5783132530120483,
      "grad_norm": 0.0,
      "learning_rate": 1.4530120481927711e-05,
      "loss": 0.0161,
      "step": 107000
    },
    {
      "epoch": 2.5903614457831328,
      "grad_norm": 2.5747568607330322,
      "learning_rate": 1.4457831325301205e-05,
      "loss": 0.019,
      "step": 107500
    },
    {
      "epoch": 2.602409638554217,
      "grad_norm": 3.692409038543701,
      "learning_rate": 1.4385542168674698e-05,
      "loss": 0.0211,
      "step": 108000
    },
    {
      "epoch": 2.6144578313253013,
      "grad_norm": 2.4071788787841797,
      "learning_rate": 1.4313253012048194e-05,
      "loss": 0.0201,
      "step": 108500
    },
    {
      "epoch": 2.6265060240963853,
      "grad_norm": 4.575064659118652,
      "learning_rate": 1.4240963855421687e-05,
      "loss": 0.0195,
      "step": 109000
    },
    {
      "epoch": 2.63855421686747,
      "grad_norm": 0.0,
      "learning_rate": 1.4168674698795181e-05,
      "loss": 0.0204,
      "step": 109500
    },
    {
      "epoch": 2.6506024096385543,
      "grad_norm": 2.6931874752044678,
      "learning_rate": 1.4096385542168676e-05,
      "loss": 0.021,
      "step": 110000
    },
    {
      "epoch": 2.662650602409639,
      "grad_norm": 0.0,
      "learning_rate": 1.402409638554217e-05,
      "loss": 0.0212,
      "step": 110500
    },
    {
      "epoch": 2.674698795180723,
      "grad_norm": 0.0,
      "learning_rate": 1.3951807228915662e-05,
      "loss": 0.0178,
      "step": 111000
    },
    {
      "epoch": 2.6867469879518073,
      "grad_norm": 0.0,
      "learning_rate": 1.3879518072289157e-05,
      "loss": 0.021,
      "step": 111500
    },
    {
      "epoch": 2.6987951807228914,
      "grad_norm": 0.0,
      "learning_rate": 1.380722891566265e-05,
      "loss": 0.0165,
      "step": 112000
    },
    {
      "epoch": 2.710843373493976,
      "grad_norm": 2.6509501934051514,
      "learning_rate": 1.3734939759036144e-05,
      "loss": 0.02,
      "step": 112500
    },
    {
      "epoch": 2.7228915662650603,
      "grad_norm": 0.0,
      "learning_rate": 1.366265060240964e-05,
      "loss": 0.0194,
      "step": 113000
    },
    {
      "epoch": 2.734939759036145,
      "grad_norm": 0.0,
      "learning_rate": 1.3590361445783133e-05,
      "loss": 0.0218,
      "step": 113500
    },
    {
      "epoch": 2.746987951807229,
      "grad_norm": 1.8614932298660278,
      "learning_rate": 1.3518072289156627e-05,
      "loss": 0.021,
      "step": 114000
    },
    {
      "epoch": 2.7590361445783134,
      "grad_norm": 0.0,
      "learning_rate": 1.3445783132530122e-05,
      "loss": 0.0207,
      "step": 114500
    },
    {
      "epoch": 2.7710843373493974,
      "grad_norm": 3.1327714920043945,
      "learning_rate": 1.3373493975903615e-05,
      "loss": 0.0179,
      "step": 115000
    },
    {
      "epoch": 2.783132530120482,
      "grad_norm": 0.0,
      "learning_rate": 1.3301204819277107e-05,
      "loss": 0.02,
      "step": 115500
    },
    {
      "epoch": 2.7951807228915664,
      "grad_norm": 0.0,
      "learning_rate": 1.3228915662650603e-05,
      "loss": 0.0176,
      "step": 116000
    },
    {
      "epoch": 2.807228915662651,
      "grad_norm": 2.475165843963623,
      "learning_rate": 1.3156626506024096e-05,
      "loss": 0.0197,
      "step": 116500
    },
    {
      "epoch": 2.819277108433735,
      "grad_norm": 1.9241726398468018,
      "learning_rate": 1.3084337349397591e-05,
      "loss": 0.0229,
      "step": 117000
    },
    {
      "epoch": 2.8313253012048194,
      "grad_norm": 0.0,
      "learning_rate": 1.3012048192771085e-05,
      "loss": 0.0167,
      "step": 117500
    },
    {
      "epoch": 2.8433734939759034,
      "grad_norm": 0.0,
      "learning_rate": 1.2939759036144579e-05,
      "loss": 0.0184,
      "step": 118000
    },
    {
      "epoch": 2.855421686746988,
      "grad_norm": 0.0,
      "learning_rate": 1.2867469879518074e-05,
      "loss": 0.0167,
      "step": 118500
    },
    {
      "epoch": 2.8674698795180724,
      "grad_norm": 2.7593395709991455,
      "learning_rate": 1.2795180722891567e-05,
      "loss": 0.0246,
      "step": 119000
    },
    {
      "epoch": 2.8795180722891565,
      "grad_norm": 0.0,
      "learning_rate": 1.2722891566265061e-05,
      "loss": 0.0177,
      "step": 119500
    },
    {
      "epoch": 2.891566265060241,
      "grad_norm": 0.0,
      "learning_rate": 1.2650602409638555e-05,
      "loss": 0.022,
      "step": 120000
    },
    {
      "epoch": 2.9036144578313254,
      "grad_norm": 0.0,
      "learning_rate": 1.2578313253012048e-05,
      "loss": 0.0172,
      "step": 120500
    },
    {
      "epoch": 2.9156626506024095,
      "grad_norm": 0.0,
      "learning_rate": 1.2506024096385542e-05,
      "loss": 0.0183,
      "step": 121000
    },
    {
      "epoch": 2.927710843373494,
      "grad_norm": 2.542802333831787,
      "learning_rate": 1.2433734939759037e-05,
      "loss": 0.0173,
      "step": 121500
    },
    {
      "epoch": 2.9397590361445785,
      "grad_norm": 0.0,
      "learning_rate": 1.236144578313253e-05,
      "loss": 0.0163,
      "step": 122000
    },
    {
      "epoch": 2.9518072289156625,
      "grad_norm": 0.0,
      "learning_rate": 1.2289156626506024e-05,
      "loss": 0.0196,
      "step": 122500
    },
    {
      "epoch": 2.963855421686747,
      "grad_norm": 0.0,
      "learning_rate": 1.221686746987952e-05,
      "loss": 0.0185,
      "step": 123000
    },
    {
      "epoch": 2.9759036144578315,
      "grad_norm": 0.0,
      "learning_rate": 1.2144578313253013e-05,
      "loss": 0.0206,
      "step": 123500
    },
    {
      "epoch": 2.9879518072289155,
      "grad_norm": 0.0,
      "learning_rate": 1.2072289156626507e-05,
      "loss": 0.0213,
      "step": 124000
    },
    {
      "epoch": 3.0,
      "grad_norm": 3.22137713432312,
      "learning_rate": 1.2e-05,
      "loss": 0.0191,
      "step": 124500
    },
    {
      "epoch": 3.0120481927710845,
      "grad_norm": 5.630899906158447,
      "learning_rate": 1.1927710843373494e-05,
      "loss": 0.0196,
      "step": 125000
    },
    {
      "epoch": 3.0240963855421685,
      "grad_norm": 0.0,
      "learning_rate": 1.1855421686746987e-05,
      "loss": 0.0148,
      "step": 125500
    },
    {
      "epoch": 3.036144578313253,
      "grad_norm": 2.9033374786376953,
      "learning_rate": 1.1783132530120483e-05,
      "loss": 0.0156,
      "step": 126000
    },
    {
      "epoch": 3.0481927710843375,
      "grad_norm": 0.0,
      "learning_rate": 1.1710843373493976e-05,
      "loss": 0.0207,
      "step": 126500
    },
    {
      "epoch": 3.0602409638554215,
      "grad_norm": 0.0,
      "learning_rate": 1.163855421686747e-05,
      "loss": 0.0163,
      "step": 127000
    },
    {
      "epoch": 3.072289156626506,
      "grad_norm": 5.180342197418213,
      "learning_rate": 1.1566265060240965e-05,
      "loss": 0.0187,
      "step": 127500
    },
    {
      "epoch": 3.0843373493975905,
      "grad_norm": 6.134942054748535,
      "learning_rate": 1.1493975903614459e-05,
      "loss": 0.0201,
      "step": 128000
    },
    {
      "epoch": 3.0963855421686746,
      "grad_norm": 3.4246160984039307,
      "learning_rate": 1.1421686746987952e-05,
      "loss": 0.0176,
      "step": 128500
    },
    {
      "epoch": 3.108433734939759,
      "grad_norm": 3.7621219158172607,
      "learning_rate": 1.1349397590361446e-05,
      "loss": 0.0191,
      "step": 129000
    },
    {
      "epoch": 3.1204819277108435,
      "grad_norm": 0.0,
      "learning_rate": 1.127710843373494e-05,
      "loss": 0.0177,
      "step": 129500
    },
    {
      "epoch": 3.1325301204819276,
      "grad_norm": 3.9125075340270996,
      "learning_rate": 1.1204819277108433e-05,
      "loss": 0.0181,
      "step": 130000
    },
    {
      "epoch": 3.144578313253012,
      "grad_norm": 0.0,
      "learning_rate": 1.1132530120481928e-05,
      "loss": 0.0193,
      "step": 130500
    },
    {
      "epoch": 3.1566265060240966,
      "grad_norm": 0.0,
      "learning_rate": 1.1060240963855422e-05,
      "loss": 0.0169,
      "step": 131000
    },
    {
      "epoch": 3.1686746987951806,
      "grad_norm": 0.0,
      "learning_rate": 1.0987951807228916e-05,
      "loss": 0.0198,
      "step": 131500
    },
    {
      "epoch": 3.180722891566265,
      "grad_norm": 3.598256826400757,
      "learning_rate": 1.0915662650602411e-05,
      "loss": 0.0182,
      "step": 132000
    },
    {
      "epoch": 3.1927710843373496,
      "grad_norm": 0.0,
      "learning_rate": 1.0843373493975904e-05,
      "loss": 0.0179,
      "step": 132500
    },
    {
      "epoch": 3.2048192771084336,
      "grad_norm": 3.5610880851745605,
      "learning_rate": 1.0771084337349398e-05,
      "loss": 0.0197,
      "step": 133000
    },
    {
      "epoch": 3.216867469879518,
      "grad_norm": 3.870453357696533,
      "learning_rate": 1.0698795180722892e-05,
      "loss": 0.0198,
      "step": 133500
    },
    {
      "epoch": 3.2289156626506026,
      "grad_norm": 0.0,
      "learning_rate": 1.0626506024096385e-05,
      "loss": 0.0165,
      "step": 134000
    },
    {
      "epoch": 3.2409638554216866,
      "grad_norm": 0.0,
      "learning_rate": 1.0554216867469879e-05,
      "loss": 0.0191,
      "step": 134500
    },
    {
      "epoch": 3.253012048192771,
      "grad_norm": 0.0,
      "learning_rate": 1.0481927710843374e-05,
      "loss": 0.0201,
      "step": 135000
    },
    {
      "epoch": 3.2650602409638556,
      "grad_norm": 0.0,
      "learning_rate": 1.0409638554216868e-05,
      "loss": 0.0167,
      "step": 135500
    },
    {
      "epoch": 3.2771084337349397,
      "grad_norm": 0.0,
      "learning_rate": 1.0337349397590361e-05,
      "loss": 0.0188,
      "step": 136000
    },
    {
      "epoch": 3.289156626506024,
      "grad_norm": 0.0,
      "learning_rate": 1.0265060240963857e-05,
      "loss": 0.0165,
      "step": 136500
    },
    {
      "epoch": 3.3012048192771086,
      "grad_norm": 0.0,
      "learning_rate": 1.019277108433735e-05,
      "loss": 0.0159,
      "step": 137000
    },
    {
      "epoch": 3.3132530120481927,
      "grad_norm": 2.5624029636383057,
      "learning_rate": 1.0120481927710844e-05,
      "loss": 0.0193,
      "step": 137500
    },
    {
      "epoch": 3.325301204819277,
      "grad_norm": 0.0,
      "learning_rate": 1.0048192771084337e-05,
      "loss": 0.0186,
      "step": 138000
    },
    {
      "epoch": 3.337349397590361,
      "grad_norm": 2.341689348220825,
      "learning_rate": 9.975903614457831e-06,
      "loss": 0.0183,
      "step": 138500
    },
    {
      "epoch": 3.3493975903614457,
      "grad_norm": 2.2599334716796875,
      "learning_rate": 9.903614457831324e-06,
      "loss": 0.0189,
      "step": 139000
    },
    {
      "epoch": 3.36144578313253,
      "grad_norm": 0.0,
      "learning_rate": 9.83132530120482e-06,
      "loss": 0.0187,
      "step": 139500
    },
    {
      "epoch": 3.3734939759036147,
      "grad_norm": 1.6956989765167236,
      "learning_rate": 9.759036144578313e-06,
      "loss": 0.0187,
      "step": 140000
    },
    {
      "epoch": 3.3855421686746987,
      "grad_norm": 2.8051908016204834,
      "learning_rate": 9.686746987951807e-06,
      "loss": 0.0152,
      "step": 140500
    },
    {
      "epoch": 3.397590361445783,
      "grad_norm": 0.0,
      "learning_rate": 9.614457831325302e-06,
      "loss": 0.017,
      "step": 141000
    },
    {
      "epoch": 3.4096385542168672,
      "grad_norm": 0.0,
      "learning_rate": 9.542168674698796e-06,
      "loss": 0.0179,
      "step": 141500
    },
    {
      "epoch": 3.4216867469879517,
      "grad_norm": 0.0,
      "learning_rate": 9.46987951807229e-06,
      "loss": 0.0168,
      "step": 142000
    },
    {
      "epoch": 3.433734939759036,
      "grad_norm": 0.0,
      "learning_rate": 9.397590361445783e-06,
      "loss": 0.016,
      "step": 142500
    },
    {
      "epoch": 3.4457831325301207,
      "grad_norm": 0.0,
      "learning_rate": 9.325301204819277e-06,
      "loss": 0.0172,
      "step": 143000
    },
    {
      "epoch": 3.4578313253012047,
      "grad_norm": 0.0,
      "learning_rate": 9.253012048192772e-06,
      "loss": 0.0185,
      "step": 143500
    },
    {
      "epoch": 3.4698795180722892,
      "grad_norm": 2.817730665206909,
      "learning_rate": 9.180722891566265e-06,
      "loss": 0.0156,
      "step": 144000
    },
    {
      "epoch": 3.4819277108433733,
      "grad_norm": 0.0,
      "learning_rate": 9.108433734939759e-06,
      "loss": 0.0163,
      "step": 144500
    },
    {
      "epoch": 3.4939759036144578,
      "grad_norm": 0.0,
      "learning_rate": 9.036144578313254e-06,
      "loss": 0.016,
      "step": 145000
    },
    {
      "epoch": 3.5060240963855422,
      "grad_norm": 0.0,
      "learning_rate": 8.963855421686748e-06,
      "loss": 0.0171,
      "step": 145500
    },
    {
      "epoch": 3.5180722891566267,
      "grad_norm": 0.0,
      "learning_rate": 8.891566265060241e-06,
      "loss": 0.0174,
      "step": 146000
    },
    {
      "epoch": 3.5301204819277108,
      "grad_norm": 6.62953519821167,
      "learning_rate": 8.819277108433737e-06,
      "loss": 0.0154,
      "step": 146500
    },
    {
      "epoch": 3.5421686746987953,
      "grad_norm": 0.0,
      "learning_rate": 8.746987951807229e-06,
      "loss": 0.0143,
      "step": 147000
    },
    {
      "epoch": 3.5542168674698793,
      "grad_norm": 0.0,
      "learning_rate": 8.674698795180722e-06,
      "loss": 0.0156,
      "step": 147500
    },
    {
      "epoch": 3.566265060240964,
      "grad_norm": 2.7751309871673584,
      "learning_rate": 8.602409638554217e-06,
      "loss": 0.0165,
      "step": 148000
    },
    {
      "epoch": 3.5783132530120483,
      "grad_norm": 3.2807881832122803,
      "learning_rate": 8.530120481927711e-06,
      "loss": 0.0174,
      "step": 148500
    },
    {
      "epoch": 3.5903614457831328,
      "grad_norm": 0.0,
      "learning_rate": 8.457831325301205e-06,
      "loss": 0.0171,
      "step": 149000
    },
    {
      "epoch": 3.602409638554217,
      "grad_norm": 0.0,
      "learning_rate": 8.3855421686747e-06,
      "loss": 0.0186,
      "step": 149500
    },
    {
      "epoch": 3.6144578313253013,
      "grad_norm": 0.0,
      "learning_rate": 8.313253012048194e-06,
      "loss": 0.0173,
      "step": 150000
    },
    {
      "epoch": 3.6265060240963853,
      "grad_norm": 0.0,
      "learning_rate": 8.240963855421687e-06,
      "loss": 0.0156,
      "step": 150500
    },
    {
      "epoch": 3.63855421686747,
      "grad_norm": 0.0,
      "learning_rate": 8.168674698795182e-06,
      "loss": 0.0186,
      "step": 151000
    },
    {
      "epoch": 3.6506024096385543,
      "grad_norm": 0.0,
      "learning_rate": 8.096385542168674e-06,
      "loss": 0.0184,
      "step": 151500
    },
    {
      "epoch": 3.662650602409639,
      "grad_norm": 2.893437147140503,
      "learning_rate": 8.024096385542168e-06,
      "loss": 0.0202,
      "step": 152000
    },
    {
      "epoch": 3.674698795180723,
      "grad_norm": 0.0,
      "learning_rate": 7.951807228915663e-06,
      "loss": 0.0158,
      "step": 152500
    },
    {
      "epoch": 3.6867469879518073,
      "grad_norm": 0.0,
      "learning_rate": 7.879518072289157e-06,
      "loss": 0.0183,
      "step": 153000
    },
    {
      "epoch": 3.6987951807228914,
      "grad_norm": 0.0,
      "learning_rate": 7.80722891566265e-06,
      "loss": 0.0193,
      "step": 153500
    },
    {
      "epoch": 3.710843373493976,
      "grad_norm": 3.2492313385009766,
      "learning_rate": 7.734939759036146e-06,
      "loss": 0.0169,
      "step": 154000
    },
    {
      "epoch": 3.7228915662650603,
      "grad_norm": 0.0,
      "learning_rate": 7.66265060240964e-06,
      "loss": 0.0185,
      "step": 154500
    },
    {
      "epoch": 3.734939759036145,
      "grad_norm": 0.0,
      "learning_rate": 7.590361445783132e-06,
      "loss": 0.0152,
      "step": 155000
    },
    {
      "epoch": 3.746987951807229,
      "grad_norm": 0.0,
      "learning_rate": 7.518072289156627e-06,
      "loss": 0.0165,
      "step": 155500
    },
    {
      "epoch": 3.7590361445783134,
      "grad_norm": 4.312481880187988,
      "learning_rate": 7.445783132530121e-06,
      "loss": 0.0155,
      "step": 156000
    },
    {
      "epoch": 3.7710843373493974,
      "grad_norm": 0.0,
      "learning_rate": 7.373493975903615e-06,
      "loss": 0.018,
      "step": 156500
    },
    {
      "epoch": 3.783132530120482,
      "grad_norm": 1.6969873905181885,
      "learning_rate": 7.301204819277108e-06,
      "loss": 0.0166,
      "step": 157000
    },
    {
      "epoch": 3.7951807228915664,
      "grad_norm": 0.0,
      "learning_rate": 7.228915662650602e-06,
      "loss": 0.0157,
      "step": 157500
    },
    {
      "epoch": 3.807228915662651,
      "grad_norm": 3.6284844875335693,
      "learning_rate": 7.156626506024097e-06,
      "loss": 0.0164,
      "step": 158000
    },
    {
      "epoch": 3.819277108433735,
      "grad_norm": 0.0,
      "learning_rate": 7.0843373493975904e-06,
      "loss": 0.0153,
      "step": 158500
    },
    {
      "epoch": 3.8313253012048194,
      "grad_norm": 0.0,
      "learning_rate": 7.012048192771085e-06,
      "loss": 0.016,
      "step": 159000
    },
    {
      "epoch": 3.8433734939759034,
      "grad_norm": 3.5219244956970215,
      "learning_rate": 6.9397590361445784e-06,
      "loss": 0.0145,
      "step": 159500
    },
    {
      "epoch": 3.855421686746988,
      "grad_norm": 0.0,
      "learning_rate": 6.867469879518072e-06,
      "loss": 0.0181,
      "step": 160000
    },
    {
      "epoch": 3.8674698795180724,
      "grad_norm": 0.0,
      "learning_rate": 6.7951807228915665e-06,
      "loss": 0.0157,
      "step": 160500
    },
    {
      "epoch": 3.8795180722891565,
      "grad_norm": 0.0,
      "learning_rate": 6.722891566265061e-06,
      "loss": 0.0166,
      "step": 161000
    },
    {
      "epoch": 3.891566265060241,
      "grad_norm": 3.7896203994750977,
      "learning_rate": 6.650602409638554e-06,
      "loss": 0.0153,
      "step": 161500
    },
    {
      "epoch": 3.9036144578313254,
      "grad_norm": 0.0,
      "learning_rate": 6.578313253012048e-06,
      "loss": 0.0163,
      "step": 162000
    },
    {
      "epoch": 3.9156626506024095,
      "grad_norm": 0.0,
      "learning_rate": 6.5060240963855425e-06,
      "loss": 0.0163,
      "step": 162500
    },
    {
      "epoch": 3.927710843373494,
      "grad_norm": 0.0,
      "learning_rate": 6.433734939759037e-06,
      "loss": 0.0167,
      "step": 163000
    },
    {
      "epoch": 3.9397590361445785,
      "grad_norm": 2.5007286071777344,
      "learning_rate": 6.3614457831325305e-06,
      "loss": 0.0158,
      "step": 163500
    },
    {
      "epoch": 3.9518072289156625,
      "grad_norm": 4.238803863525391,
      "learning_rate": 6.289156626506024e-06,
      "loss": 0.0165,
      "step": 164000
    },
    {
      "epoch": 3.963855421686747,
      "grad_norm": 0.0,
      "learning_rate": 6.2168674698795185e-06,
      "loss": 0.0163,
      "step": 164500
    },
    {
      "epoch": 3.9759036144578315,
      "grad_norm": 2.225722312927246,
      "learning_rate": 6.144578313253012e-06,
      "loss": 0.0174,
      "step": 165000
    },
    {
      "epoch": 3.9879518072289155,
      "grad_norm": 0.0,
      "learning_rate": 6.0722891566265066e-06,
      "loss": 0.0182,
      "step": 165500
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.0,
      "learning_rate": 6e-06,
      "loss": 0.016,
      "step": 166000
    },
    {
      "epoch": 4.0120481927710845,
      "grad_norm": 0.0,
      "learning_rate": 5.927710843373494e-06,
      "loss": 0.0163,
      "step": 166500
    },
    {
      "epoch": 4.024096385542169,
      "grad_norm": 5.542412757873535,
      "learning_rate": 5.855421686746988e-06,
      "loss": 0.0151,
      "step": 167000
    },
    {
      "epoch": 4.036144578313253,
      "grad_norm": 0.0,
      "learning_rate": 5.783132530120483e-06,
      "loss": 0.0166,
      "step": 167500
    },
    {
      "epoch": 4.048192771084337,
      "grad_norm": 0.0,
      "learning_rate": 5.710843373493976e-06,
      "loss": 0.015,
      "step": 168000
    },
    {
      "epoch": 4.0602409638554215,
      "grad_norm": 0.0,
      "learning_rate": 5.63855421686747e-06,
      "loss": 0.0168,
      "step": 168500
    },
    {
      "epoch": 4.072289156626506,
      "grad_norm": 2.167665481567383,
      "learning_rate": 5.566265060240964e-06,
      "loss": 0.0154,
      "step": 169000
    },
    {
      "epoch": 4.0843373493975905,
      "grad_norm": 0.0,
      "learning_rate": 5.493975903614458e-06,
      "loss": 0.014,
      "step": 169500
    },
    {
      "epoch": 4.096385542168675,
      "grad_norm": 0.0,
      "learning_rate": 5.421686746987952e-06,
      "loss": 0.015,
      "step": 170000
    },
    {
      "epoch": 4.108433734939759,
      "grad_norm": 0.0,
      "learning_rate": 5.349397590361446e-06,
      "loss": 0.0182,
      "step": 170500
    },
    {
      "epoch": 4.120481927710843,
      "grad_norm": 0.0,
      "learning_rate": 5.277108433734939e-06,
      "loss": 0.0166,
      "step": 171000
    },
    {
      "epoch": 4.132530120481928,
      "grad_norm": 0.0,
      "learning_rate": 5.204819277108434e-06,
      "loss": 0.0142,
      "step": 171500
    },
    {
      "epoch": 4.144578313253012,
      "grad_norm": 0.0,
      "learning_rate": 5.132530120481928e-06,
      "loss": 0.016,
      "step": 172000
    },
    {
      "epoch": 4.156626506024097,
      "grad_norm": 0.0,
      "learning_rate": 5.060240963855422e-06,
      "loss": 0.0147,
      "step": 172500
    },
    {
      "epoch": 4.168674698795181,
      "grad_norm": 0.0,
      "learning_rate": 4.9879518072289154e-06,
      "loss": 0.0192,
      "step": 173000
    },
    {
      "epoch": 4.180722891566265,
      "grad_norm": 3.095973253250122,
      "learning_rate": 4.91566265060241e-06,
      "loss": 0.0169,
      "step": 173500
    },
    {
      "epoch": 4.192771084337349,
      "grad_norm": 0.0,
      "learning_rate": 4.8433734939759035e-06,
      "loss": 0.0148,
      "step": 174000
    },
    {
      "epoch": 4.204819277108434,
      "grad_norm": 0.0,
      "learning_rate": 4.771084337349398e-06,
      "loss": 0.0162,
      "step": 174500
    },
    {
      "epoch": 4.216867469879518,
      "grad_norm": 0.0,
      "learning_rate": 4.6987951807228915e-06,
      "loss": 0.0157,
      "step": 175000
    },
    {
      "epoch": 4.228915662650603,
      "grad_norm": 0.0,
      "learning_rate": 4.626506024096386e-06,
      "loss": 0.0178,
      "step": 175500
    },
    {
      "epoch": 4.240963855421687,
      "grad_norm": 0.0,
      "learning_rate": 4.5542168674698795e-06,
      "loss": 0.0178,
      "step": 176000
    },
    {
      "epoch": 4.253012048192771,
      "grad_norm": 0.0,
      "learning_rate": 4.481927710843374e-06,
      "loss": 0.0141,
      "step": 176500
    },
    {
      "epoch": 4.265060240963855,
      "grad_norm": 3.0026392936706543,
      "learning_rate": 4.409638554216868e-06,
      "loss": 0.0165,
      "step": 177000
    },
    {
      "epoch": 4.27710843373494,
      "grad_norm": 0.0,
      "learning_rate": 4.337349397590361e-06,
      "loss": 0.0139,
      "step": 177500
    },
    {
      "epoch": 4.289156626506024,
      "grad_norm": 0.0,
      "learning_rate": 4.2650602409638555e-06,
      "loss": 0.0144,
      "step": 178000
    },
    {
      "epoch": 4.301204819277109,
      "grad_norm": 0.0,
      "learning_rate": 4.19277108433735e-06,
      "loss": 0.0155,
      "step": 178500
    },
    {
      "epoch": 4.313253012048193,
      "grad_norm": 0.0,
      "learning_rate": 4.1204819277108436e-06,
      "loss": 0.0167,
      "step": 179000
    },
    {
      "epoch": 4.325301204819277,
      "grad_norm": 3.0062291622161865,
      "learning_rate": 4.048192771084337e-06,
      "loss": 0.0169,
      "step": 179500
    },
    {
      "epoch": 4.337349397590361,
      "grad_norm": 0.0,
      "learning_rate": 3.975903614457832e-06,
      "loss": 0.0161,
      "step": 180000
    },
    {
      "epoch": 4.349397590361446,
      "grad_norm": 0.0,
      "learning_rate": 3.903614457831325e-06,
      "loss": 0.0137,
      "step": 180500
    },
    {
      "epoch": 4.36144578313253,
      "grad_norm": 0.0,
      "learning_rate": 3.83132530120482e-06,
      "loss": 0.0152,
      "step": 181000
    },
    {
      "epoch": 4.373493975903615,
      "grad_norm": 0.0,
      "learning_rate": 3.7590361445783136e-06,
      "loss": 0.02,
      "step": 181500
    },
    {
      "epoch": 4.385542168674699,
      "grad_norm": 4.406426906585693,
      "learning_rate": 3.6867469879518076e-06,
      "loss": 0.018,
      "step": 182000
    },
    {
      "epoch": 4.397590361445783,
      "grad_norm": 0.0,
      "learning_rate": 3.614457831325301e-06,
      "loss": 0.0169,
      "step": 182500
    },
    {
      "epoch": 4.409638554216867,
      "grad_norm": 0.0,
      "learning_rate": 3.5421686746987952e-06,
      "loss": 0.0165,
      "step": 183000
    },
    {
      "epoch": 4.421686746987952,
      "grad_norm": 0.0,
      "learning_rate": 3.4698795180722892e-06,
      "loss": 0.0163,
      "step": 183500
    },
    {
      "epoch": 4.433734939759036,
      "grad_norm": 3.140902042388916,
      "learning_rate": 3.3975903614457832e-06,
      "loss": 0.0128,
      "step": 184000
    },
    {
      "epoch": 4.445783132530121,
      "grad_norm": 3.4312920570373535,
      "learning_rate": 3.325301204819277e-06,
      "loss": 0.0158,
      "step": 184500
    },
    {
      "epoch": 4.457831325301205,
      "grad_norm": 3.9876303672790527,
      "learning_rate": 3.2530120481927713e-06,
      "loss": 0.0164,
      "step": 185000
    },
    {
      "epoch": 4.469879518072289,
      "grad_norm": 3.2426018714904785,
      "learning_rate": 3.1807228915662653e-06,
      "loss": 0.0156,
      "step": 185500
    },
    {
      "epoch": 4.481927710843373,
      "grad_norm": 2.1818652153015137,
      "learning_rate": 3.1084337349397593e-06,
      "loss": 0.0145,
      "step": 186000
    },
    {
      "epoch": 4.493975903614458,
      "grad_norm": 0.0,
      "learning_rate": 3.0361445783132533e-06,
      "loss": 0.0175,
      "step": 186500
    },
    {
      "epoch": 4.506024096385542,
      "grad_norm": 0.0,
      "learning_rate": 2.963855421686747e-06,
      "loss": 0.0143,
      "step": 187000
    },
    {
      "epoch": 4.518072289156627,
      "grad_norm": 0.0,
      "learning_rate": 2.8915662650602413e-06,
      "loss": 0.018,
      "step": 187500
    },
    {
      "epoch": 4.530120481927711,
      "grad_norm": 0.0,
      "learning_rate": 2.819277108433735e-06,
      "loss": 0.0139,
      "step": 188000
    },
    {
      "epoch": 4.542168674698795,
      "grad_norm": 0.0,
      "learning_rate": 2.746987951807229e-06,
      "loss": 0.019,
      "step": 188500
    },
    {
      "epoch": 4.554216867469879,
      "grad_norm": 0.0,
      "learning_rate": 2.674698795180723e-06,
      "loss": 0.0123,
      "step": 189000
    },
    {
      "epoch": 4.566265060240964,
      "grad_norm": 3.5578806400299072,
      "learning_rate": 2.602409638554217e-06,
      "loss": 0.0166,
      "step": 189500
    },
    {
      "epoch": 4.578313253012048,
      "grad_norm": 0.0,
      "learning_rate": 2.530120481927711e-06,
      "loss": 0.017,
      "step": 190000
    },
    {
      "epoch": 4.590361445783133,
      "grad_norm": 0.0,
      "learning_rate": 2.457831325301205e-06,
      "loss": 0.0135,
      "step": 190500
    },
    {
      "epoch": 4.602409638554217,
      "grad_norm": 0.0,
      "learning_rate": 2.385542168674699e-06,
      "loss": 0.0148,
      "step": 191000
    },
    {
      "epoch": 4.614457831325301,
      "grad_norm": 2.8100414276123047,
      "learning_rate": 2.313253012048193e-06,
      "loss": 0.0168,
      "step": 191500
    },
    {
      "epoch": 4.626506024096385,
      "grad_norm": 0.0,
      "learning_rate": 2.240963855421687e-06,
      "loss": 0.018,
      "step": 192000
    },
    {
      "epoch": 4.63855421686747,
      "grad_norm": 0.0,
      "learning_rate": 2.1686746987951806e-06,
      "loss": 0.0134,
      "step": 192500
    },
    {
      "epoch": 4.650602409638554,
      "grad_norm": 0.0,
      "learning_rate": 2.096385542168675e-06,
      "loss": 0.0173,
      "step": 193000
    },
    {
      "epoch": 4.662650602409639,
      "grad_norm": 2.678367853164673,
      "learning_rate": 2.0240963855421686e-06,
      "loss": 0.0144,
      "step": 193500
    },
    {
      "epoch": 4.674698795180722,
      "grad_norm": 0.0,
      "learning_rate": 1.9518072289156626e-06,
      "loss": 0.0138,
      "step": 194000
    },
    {
      "epoch": 4.686746987951807,
      "grad_norm": 0.0,
      "learning_rate": 1.8795180722891568e-06,
      "loss": 0.0122,
      "step": 194500
    },
    {
      "epoch": 4.698795180722891,
      "grad_norm": 3.283273935317993,
      "learning_rate": 1.8072289156626506e-06,
      "loss": 0.0157,
      "step": 195000
    },
    {
      "epoch": 4.710843373493976,
      "grad_norm": 2.6983325481414795,
      "learning_rate": 1.7349397590361446e-06,
      "loss": 0.0155,
      "step": 195500
    },
    {
      "epoch": 4.72289156626506,
      "grad_norm": 0.0,
      "learning_rate": 1.6626506024096384e-06,
      "loss": 0.0187,
      "step": 196000
    },
    {
      "epoch": 4.734939759036145,
      "grad_norm": 3.4439845085144043,
      "learning_rate": 1.5903614457831326e-06,
      "loss": 0.016,
      "step": 196500
    },
    {
      "epoch": 4.746987951807229,
      "grad_norm": 0.0,
      "learning_rate": 1.5180722891566266e-06,
      "loss": 0.0159,
      "step": 197000
    },
    {
      "epoch": 4.759036144578313,
      "grad_norm": 2.9300475120544434,
      "learning_rate": 1.4457831325301207e-06,
      "loss": 0.0152,
      "step": 197500
    },
    {
      "epoch": 4.771084337349397,
      "grad_norm": 0.0,
      "learning_rate": 1.3734939759036144e-06,
      "loss": 0.0156,
      "step": 198000
    },
    {
      "epoch": 4.783132530120482,
      "grad_norm": 2.8579046726226807,
      "learning_rate": 1.3012048192771085e-06,
      "loss": 0.0116,
      "step": 198500
    },
    {
      "epoch": 4.795180722891566,
      "grad_norm": 0.0,
      "learning_rate": 1.2289156626506025e-06,
      "loss": 0.0161,
      "step": 199000
    },
    {
      "epoch": 4.807228915662651,
      "grad_norm": 0.0,
      "learning_rate": 1.1566265060240965e-06,
      "loss": 0.0193,
      "step": 199500
    },
    {
      "epoch": 4.8192771084337345,
      "grad_norm": 0.0,
      "learning_rate": 1.0843373493975903e-06,
      "loss": 0.0154,
      "step": 200000
    },
    {
      "epoch": 4.831325301204819,
      "grad_norm": 0.0,
      "learning_rate": 1.0120481927710843e-06,
      "loss": 0.0164,
      "step": 200500
    },
    {
      "epoch": 4.843373493975903,
      "grad_norm": 0.0,
      "learning_rate": 9.397590361445784e-07,
      "loss": 0.0153,
      "step": 201000
    },
    {
      "epoch": 4.855421686746988,
      "grad_norm": 0.0,
      "learning_rate": 8.674698795180723e-07,
      "loss": 0.0137,
      "step": 201500
    },
    {
      "epoch": 4.867469879518072,
      "grad_norm": 3.969184637069702,
      "learning_rate": 7.951807228915663e-07,
      "loss": 0.0154,
      "step": 202000
    },
    {
      "epoch": 4.879518072289157,
      "grad_norm": 0.0,
      "learning_rate": 7.228915662650603e-07,
      "loss": 0.0167,
      "step": 202500
    },
    {
      "epoch": 4.891566265060241,
      "grad_norm": 2.980910062789917,
      "learning_rate": 6.506024096385542e-07,
      "loss": 0.0146,
      "step": 203000
    },
    {
      "epoch": 4.903614457831325,
      "grad_norm": 0.0,
      "learning_rate": 5.783132530120482e-07,
      "loss": 0.0167,
      "step": 203500
    },
    {
      "epoch": 4.9156626506024095,
      "grad_norm": 3.575998306274414,
      "learning_rate": 5.060240963855421e-07,
      "loss": 0.0175,
      "step": 204000
    },
    {
      "epoch": 4.927710843373494,
      "grad_norm": 0.0,
      "learning_rate": 4.3373493975903615e-07,
      "loss": 0.0143,
      "step": 204500
    },
    {
      "epoch": 4.9397590361445785,
      "grad_norm": 0.0,
      "learning_rate": 3.6144578313253016e-07,
      "loss": 0.0139,
      "step": 205000
    },
    {
      "epoch": 4.951807228915663,
      "grad_norm": 0.0,
      "learning_rate": 2.891566265060241e-07,
      "loss": 0.0174,
      "step": 205500
    },
    {
      "epoch": 4.9638554216867465,
      "grad_norm": 0.0,
      "learning_rate": 2.1686746987951808e-07,
      "loss": 0.0151,
      "step": 206000
    },
    {
      "epoch": 4.975903614457831,
      "grad_norm": 0.0,
      "learning_rate": 1.4457831325301206e-07,
      "loss": 0.0128,
      "step": 206500
    },
    {
      "epoch": 4.9879518072289155,
      "grad_norm": 0.0,
      "learning_rate": 7.228915662650603e-08,
      "loss": 0.0143,
      "step": 207000
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.0,
      "learning_rate": 0.0,
      "loss": 0.0144,
      "step": 207500
    }
  ],
  "logging_steps": 500,
  "max_steps": 207500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
